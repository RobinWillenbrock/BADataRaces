\documentclass[
%%%%% Styles and Sizes
%10pt,
%11pt,
%12pt,
fancyheadings, % headings with seplines and logo
%
%%%%% Printing, Color and Binding
%a4paper, 
%a5paper,
%twoside, % single sided printout
%oneside, % duplex printout (default)
%% binding correction is used to compensate for the paper lost during binding
%% of the document
%BCOR=0.7cm, % binding correction
%nobcorignoretitle, % do not ignore BCOR for title page
%% the following two options only concern the graphics included by the document
%% class
%grayscaletitle, % keep the title in grayscale
%grayscalebody, % keep the rest of the document in grayscale
%
%%%%% expert options: your mileage may vary
%baseclass=..., % special option to use a different document baseclass
]{stsreprt}

% Information for the Titlepage
\author{Robin Willenbrock}
\title{Static Detection of Data Races in Interrupt-Driven Software Using Reduced Inter-Procedural Control Flow Graphs}
\date{\today}
\subject{Bachelor Thesis}
\professor{Prof. Dr. Sibylle Schupp }
\advisor{Ulrike Engeln}

\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{xcolor}
% Font and Fontencoding Magic
% FAQ: 
% http://tex.stackexchange.com/questions/664/why-should-i-use-usepackaget1fontenc
% http://en.wikipedia.org/wiki/Computer_Modern
% http://tex.stackexchange.com/questions/1390/latin-modern-vs-cm-super
\usepackage[T1]{fontenc}
\usepackage{lmodern}
%\usepackage{fix-cm}
\lstset{
	language=Python,
	basicstyle=\ttfamily\footnotesize,
	keywordstyle=\color{blue},
	commentstyle=\color{green},
	stringstyle=\color{red},
	numbers=left,
	numberstyle=\tiny\color{gray},
	stepnumber=1,
	numbersep=5pt,
	frame=single,
	breaklines=true,
	showstringspaces=false,
	tabsize=4,
	captionpos=b
}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows, positioning}
\usepackage{caption}
\usepackage{float}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\raggedbottom

\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm,text centered, draw=black, fill=red!30]
\tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=orange!30]
\tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!30]
\tikzstyle{arrow} = [thick,->,>=stealth]
\tikzstyle{redarrow} = [thick,->,>=stealth,draw=red]

% Package for Abbreviations
\usepackage{acronym}
\usepackage{hyperref} 

\begin{document}
	\frontmatter
	\maketitle
	\tableofcontents
	\listoffigures{}
	\listofalgorithms
	
	% Abbreviations
	\chapter*{Abbreviations}
	\begin{acronym}
		\acro{ISR}{interrupt service routine}
		\acro{CFG}{control flow graph}
		\acro{ICFG}{inter-procedural control flow graph}
		\acro{RICFG}{reduced inter-procedural control flow graph}
		\acro{GCC}{GNU Compiler Collection}
		\acro{DFS}{depth-first search}
		\acro{BB}{basic block}
	\end{acronym}
	
	\mainmatter{
		\chapter{Introduction}
		Interrupt-driven architectures are crucial in modern software development for timley responses to unpredictable events. These systems often use \acp{ISR} to handle such events, to achive the execution of critical tasks with a minimal delay. However, the concurrent nature of \acp{ISR} and the executed program can lead to synchronization issues. Data races are one of those critical issues. They can occur when two or more function or \acp{ISR} access the same shared resource and potentially lead to inconsistency and unpredictable behavior of the program.
		
		Preventing those problems makes the detection of data races vital for realiable and correct execution of software. Static analysis provides an efficient approach of detecting data races in the development process.
		
		This thesis presents a static data race detection framework specified for interrupt-driven software. The framework uses \acp{RICFG} to efficiently represent the control flow of the program. By analyzing those graphs, paths where shared resources are accessed concurrently without proper synchonization, are identified and inidicate possible data races. The paths are explored by using a \ac{DFS} algorithm, which ensures the traversion of every possible path. Additionally, a mechanism to handle enabling and disabling \acp{ISR}, a common practice to ensure data consistency in interrupt-driven systems, is implemented.
		
		This thesis is providing a chapter with important backround informations to help understand the overall problem of data races. That chapter is giving a introduction into the topic of interrupt-driven systems, shared resources, \aclp{RICFG} and data races.
		
		With the basic knowledge of data races provided, the thesis is going to give an in depth explanation of the implementation of the static analysis framework, using algorithms of the implementation to enhance the understanding of the framework.
		
		The implementation is then evaluated by using public benchmarks and self generated ones to cover a wide spectrum of possible cases.
		Following the evaluation the results of the framework are discussed, including a overview of the done work and showing possible improvements to the analysis tool that could be done in future work. In the end the thesis is finallized in an conclusion.
		
		\chapter{Background}
		This chapter provides a brief overview of all the necessary background information needed to understand static data races in interrupt-driven software using \aclp{RICFG}. This information includes basics about interrupt-driven systems, shared resources, \acp{RICFG}, and data races as a whole.
		
		\section{Interrupt-Driven Systems}
		An interrupt-driven system is an architecture where the flow of execution is determined by unpredictable events in the system, also known as interrupts. Interrupts can be caused by hardware devices, software conditions, or external signals, forcing the processor to suspend the current task to execute an interrupt handler or \acl{ISR}. Interrupt-driven systems are used in real-time operating systems, embedded systems, and generally in systems where timely or event-driven responses are necessary \cite{wang2020}.
		
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[node distance=2cm, scale=0.75, transform shape]
				
				\node (start) [startstop] {Start};
				\node (init) [process, below of=start] {Initialize System};
				\node (exec) [process, below of=init] {Execute Function};
				\node (interrupt) [decision, below of=exec, yshift=-0.8cm] {Interrupt Occurs?};
				\node (isr) [process, below of=interrupt, yshift=-0.8cm] {Execute ISR};
				\node (resume) [process, below of=isr] {Resume Function};
				\node (end) [startstop, below of=resume] {End};
				
				\draw [arrow] (start) -- (init);
				\draw [arrow] (init) -- (exec);
				\draw [arrow] (exec) -- (interrupt);
				\draw [arrow] (interrupt) -- node[anchor=east] {Yes} (isr);
				\draw [arrow] (isr) -- (resume);
				\draw [arrow] (resume) -- (end);
				\draw [arrow] (resume.east) -- ++(1.5,0) node[anchor=north] {}  |- (exec.east);
				
			\end{tikzpicture}
			\caption{Flowchart of the Interrupt-Driven System}
			\label{fig:ids}
		\end{figure}
		
		In Figure \ref{fig:ids}, a basic execution flow of a simple interrupt-driven system is displayed. The system executes a function as long as no interrupt occurs. When an interrupt occurs, it switches to the \ac{ISR}, executes it, and then resumes the function executed before the interrupt happened.
		
		The management of interrupts to maintain the fast responsiveness of the system is the most challenging part of an interrupt-driven system. Interrupts occur in unpredictable ways, so you have to consider every possible execution flow. To ensure the execution of critical interrupts, interrupts are often prioritized, so higher-priority events can interrupt lower ones and be handled immediately. When handling an interrupt, the current state of the processor is saved, and the context is switched to the \ac{ISR} \cite{wang2020}.
		
		The unpredictability and asynchronous nature of interrupts present many challenges in designing and implementing an interrupt-driven system. One of the biggest challenges is the correct handling of high-priority interrupts without delaying them substantially, which requires a sophisticated scheduling and prioritization mechanism. 
		To conclude in an interrupt-driven system, the execution of the main program and \ac{ISR} needs to be handled properly to ensure data integrity. 
		
		\section{Shared Resources}
		Analyzing the management of shared resources is a large part of data race analysis, which is further explained later. The following is a short introduction to shared resources to better understand them in the context of data races.
		
		Shared resources, often referred to as shared memory or shared variables, are data that can be accessed simultaneously by multiple threads or processes. Proper management of these resources is crucial because improper handling can lead to issues like data races, deadlocks, and other synchronization problems. In interrupt-driven systems, shared resources often involve variables or data structures that are accessed by both the main program and \acp{ISR}. Proper management of shared resources is critical to ensure data consistency and avoiding conflicts \cite{herlihy2008}.
		
		Proper management of shared resources involves the use of synchronization mechanisms to coordinate access and ensure data consistency. Mutexes, semaphores, and condition variables are common tools used to control access to shared resources. Mutexes provide mutual exclusion, ensuring that only one thread can access the resource at a time. Semaphores can limit the number of threads accessing the resource simultaneously. Condition variables allow threads to wait for certain conditions to be met before proceeding, facilitating complex synchronization scenarios \cite{herlihy2008}. In interrupt-driven software, the synchronization of shared resources often involves disabling interrupts while accessing shared data \cite{chopra2019}.
		
		\section{Reduced Inter-Procedural Control Flow Graphs}
		Control flow graphs (\acp{CFG}) are representations of all possible paths through a program or function during its execution. An \acp{ICFG} adds possible edges between multiple programs or functions to also show possible control flows between those.\\
		An \acl{ICFG} is a directed graph $G = (V, E)$ where:
		\begin{itemize}
			\item $V$ is the set of vertices. Each vertex represents a \ac{BB} within a procedure or function.
			\item $E$ is the set of directed edges. Each edge $(u, v)$ represents a possible flow of control from block $u$ to block $v$. These edges include:
			\begin{itemize}
				\item Intra-procedural edges represent control flow within a single function.
				\item Call edges represent the calling of a function \cite{mehl2008}.
			\end{itemize}
		\end{itemize}
		 A \ac{RICFG} is an optimized version of the ICFG that simplifies the graph to only the necessary information needed for the analysis \cite{engler2003}.
		
		\begin{figure}[H]

			\centering
			\begin{tikzpicture}[node distance=2cm, scale=0.85, transform shape]
				
				% Nodes for main function
				\node (start) [startstop] {Start main()};
				\node (init) [process, below of=start] {Initialize};
				\node (callsidefunction) [process, below of=init] {Call sidefunction()};
				\node (resume) [process, below of=callsidefunction, yshift=-0.5cm] {Resume main()};
				\node (end) [startstop, below of=resume] {End main()};
				
				% Nodes for sidefunction
				\node (startsidefunction) [startstop, right of=callsidefunction, xshift=4cm, yshift=4cm] {Start sidefunction()};
				\node (processsidefunction) [process, below of=startsidefunction] {Process in sidefunction()};
				\node (endsidefunction) [startstop, below of=processsidefunction] {End sidefunction()};
				
				% Arrows for main function
				\draw [arrow] (start) -- (init);
				\draw [arrow] (init) -- (callsidefunction);
				\draw [arrow] (callsidefunction) -- (resume);
				\draw [arrow] (resume) -- (end);
				
				% Arrows for sidefunction
				\draw [arrow] (startsidefunction) -- (processsidefunction);
				\draw [arrow] (processsidefunction) -- (endsidefunction);
				
				% Interprocedural arrows
				\draw [arrow] (callsidefunction.east) -- ++(1,0) |- (startsidefunction);
				\draw [arrow] (endsidefunction.west) -- ++(-1,0) |- (resume);
				
				% Labels
				\node [above of=start, yshift=0.5cm, text centered] {\textbf{main() function}};
				\node [above of=startsidefunction, yshift=0.5cm, xshift=0cm, text centered] {\textbf{sidefunction()}};
				
			\end{tikzpicture}
			\caption{Example of an Inter-Procedural Control Flow Graph}
			\label{icfg}
		\end{figure}
		
		In Figure \ref{icfg}, a simple \ac{ICFG} is shown. There are two separate linear control flow graphs where the main function calls the side function in its execution. To interpret the flow of the program correctly, you need to consider the execution of sidefunction() and where it's called. The ICFG combines the two separate CFGs to ensure correct analysis.
		
		\subsection{Reduction of Control Flow Graphs}
		There are multiple techniques to reduce the graph, such as node merging, edge contraction, and the elimination of non-important nodes, without losing any information required for the analysis and reducing the complexity of the RICFG. The reduction of the ICFG makes the analysis of large and complex software a lot more efficient. By minimizing the amount of data while retaining enough detail, RICFGs are great for static analysis of data races \cite{wang2020}.
		
		Node merging involves combining nodes that represent redundant control flow paths to reduce the number of nodes in the graph. Edge contraction simplifies the graph by reducing the number of edges between nodes. It collapses edges that do not significantly affect the control flow of the graph \cite{muchnick1997}. The elimination of nodes is the main tool used in this work to reduce the CFG. Eliminating nodes that do not carry any essential information for the applied data analysis significantly reduces the amount of data the algorithm has to analyze. Overall, these techniques enhance the scalability of static analysis and make it more practical to analyze more complex data structures \cite{wang2020}.
		
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[node distance=2cm, scale=0.75, transform shape]
				
				% Nodes for main function
				\node (start) [startstop] {Start main()};
				\node (init) [process, below of=start] {Initialize};
				\node (unimportant_main) [process, below of=init] {Reduced path};
				\node (callisr1) [process, below of=unimportant_main, yshift=-0.5cm] {Call sidefunction()};
				\node (resume) [process, below of=callisr1, yshift=-0.5cm] {Resume main()};
				\node (end) [startstop, below of=resume] {End main()};
				
				% Nodes for \ac{ISR}1 function
				\node (startisr1) [startstop, right of=callisr1, xshift=4cm, yshift=6.5cm] {Start sidefunction()};
				\node (unimportant_isr1) [process, below of=startisr1] {Reduced path};
				\node (processisr1) [process, below of=unimportant_isr1] {Process in sidefunction()};
				\node (endisr1) [startstop, below of=processisr1] {End sidefunction()};
				
				% Arrows for main function
				\draw [arrow] (start) -- (init);
				\draw [arrow] (init) -- (unimportant_main);
				\draw [arrow] (unimportant_main) -- (callisr1);
				\draw [arrow] (callisr1) -- (resume);
				\draw [arrow] (resume) -- (end);
				
				% Arrows for \ac{ISR}1 function
				\draw [arrow] (startisr1) -- (unimportant_isr1);
				\draw [arrow] (unimportant_isr1) -- (processisr1);
				\draw [arrow] (processisr1) -- (endisr1);
				
				% Interprocedural arrows
				\draw [arrow] (callisr1.east) -- ++(1,0) |- (startisr1);
				\draw [arrow] (endisr1.west) -- ++(-1,0) |- (resume);
				
				% Red arrows bypassing unimportant information
				\draw [redarrow] (init.west) -- ++(-1,0) |- (callisr1.west);
				\draw [redarrow] (startisr1.east) -- ++(1,0) |- (processisr1.east);
				
				% Red crosses over unimportant information
				\draw[red,thick] (unimportant_main.north west) -- (unimportant_main.south east);
				\draw[red,thick] (unimportant_main.north east) -- (unimportant_main.south west);
				\draw[red,thick] (unimportant_isr1.north west) -- (unimportant_isr1.south east);
				\draw[red,thick] (unimportant_isr1.north east) -- (unimportant_isr1.south west);
				
				% Labels
				\node [above of=start, yshift=0.5cm, text centered] {\textbf{main() function}};
				\node [above of=startisr1, yshift=0.5cm, xshift=0cm, text centered] {\textbf{sidefunction()}};
				
			\end{tikzpicture}
			\caption{Example of a Reduced Inter-Procedural Control Flow Graph}
			\label{ricfg}
		\end{figure}
		
		Figure \ref{ricfg} shows the example of a simple \ac{ICFG} with added unneccessary nodes. The resulting \ac{RICFG} reduces the \ac{CFG} by eliminating the nodes that do not carry any important information for the analysis the \ac{RICFG} is used for. It also adds new edges to skip the deleted nodes.
		 
		\subsection{Depth-First Search}
		\ac{DFS} is an algorithm used to traverse a graph systematically. It begins at a source node and extends its exploration through the connected nodes as far as possible before it backtracks. In an algorithm this can be implemented using a recursive approach. The basic idea is to mark a node when its first discovered and then explore all the adjacent nodes that are not visited before. 
		
		\begin{algorithm}[H]
			\label{algo:dfs}
			\caption{Depth-First Search}
			\SetAlgoLined
			\SetKwFunction{FMain}{dfs\_main}
			\SetKwFunction{DFS}{dfs}
			\SetKwProg{Fn}{Function}{:}{}
			
			\Fn{\DFS{node, visited}}{
				visited[node] = True\;
				\For{neighbor \textbf{in} graph[node]}{
					\If{not visited[neighbor]}{
						\DFS{neighbor, visited}\;
					}
				}
			}
		\end{algorithm}
		
		In Algorithm \ref{algo:dfs} a simple example of a \ac{DFS} is shown. The \texttt{dfs} function gets called with the root node of a tree and performs the \ac{DFS} starting from the given node. It recursively calls itself with a new node called \texttt{neighbor} and repeats this until all the reachable nodes are marked as visited \cite{mehl2008}.
		
		
		\section{Data Races}
		
		A data race occurs when two or more functions or threads access a shared resource concurrently, without being ordered by a happens-before relationship, and one of those accesses is a write operation \cite{chen2011}. A happens-before relationship ensures that, if there are two operations A and B and they are related in a happens-before relationship A has to finish before B can start. Data races can lead to unpredictable behavior and errors in the system, which makes the detection of data races a critical aspect of concurrent programs. Without proper synchronization, a system with multiple threads or functions that use shared data may lead to data races. The outcome of a interrupt-driven program with data races is non-deterministic \cite{chen2011}. The order of execution of operations vary, which may result in bugs that are not reproducible or difficult to reproduce. 
		\newpage
		
		This is a simple example of a possible data races between a \texttt{main} function and an \texttt{isr} function.
		\begin{lstlisting}
			# Data Race Example
			long shared1 = 0
			
			def main():
			
			unsigned tmp = 0
			
			tmp = shared1
			
			def isr1():
			
			idlerun()
			shared1 = 1
			idlerun()
			
			main()
		\end{lstlisting}
			
		
		A global variable \texttt{shared1} is initiated and accessed in two different functions, \texttt{main()} and \texttt{isr1()}. Since there are no synchronization tools used and the operation in \texttt{isr1} is a write, there is a data race between line 5 and line 9.
		
		\subsection{Detection Techniques}
		
		Data race detection can be approached by two different analytical methods. Each of these methods provides benefits and challenges.
		
		\subsubsection{Static Data Race Detection}
		Static data race detection involves analyzing the source code of a program without executing it to identify potential race conditions, which are situations where the outcome of a program depends on the timing of uncontrollable events like thread execution order. \\
		\textbf{Advantages:}
		\begin{itemize}
			\item Comprehensiveness: Static analysis inspects the code without executing the program by analyzing every possible execution path and interaction that could lead to data races.
			\item Early Detection: Since static analysis does not require execution, it can analyze the code in the development phase, allowing the developer to find issues without deployment.
		\end{itemize}
		\textbf{Disadvantages:}
		\begin{itemize}
			\item False Positives/Negatives: Static analysis reports all data races that fall under certain conditions. Some of these data races could be very unlikely or even impossible at runtime. On the other hand, due to the approximations and assumptions necessary for tractability, it may miss some races.
			\item Complexity in Handling Dynamic Behavior: Dynamic behaviors such as pointers or recursion can be challenging to analyze for static approaches, leading to incomplete or inaccurate results \cite{wang2020}.
		\end{itemize}
		
		\subsubsection{Dynamic Data Race Detection}
		Dynamic data race detection, on the other hand, involves monitoring the execution of a program in real-time to detect actual race conditions as they occur, relying on runtime information to identify conflicts in memory access by concurrent threads. \\
		\textbf{Advantages:}
		\begin{itemize}
			\item Precision: Dynamic analysis tools monitor the actual execution of a program, identifying data races in real-time, which reduces the number of false positives.
			\item Context-Sensitive Detection: By analyzing the actual runtime behavior, dynamic analysis can understand the context of operations, leading to more accurate detection.
		\end{itemize}
		\textbf{Disadvantages:}
		\begin{itemize}
			\item Performance Overhead: The analysis at runtime can slow down the application significantly.
			\item Coverage: The effectiveness is heavily dependent on the execution path triggered during the tests. If certain parts of the program are not passed through in the execution run, they are not analyzed \cite{flanagan2009}.
		\end{itemize}
		
		Both static and dynamic analyses are crucial for a complete analysis of code. They complement each other's limitations. A combination of both is the best approach to detect data races most reliably. However, this work, is going to focus on the static analysis of data races.
		
		\subsection{Strategies for Preventing Data Races}
		
		Preventing data races requires careful design and implementation of concurrent programs. Effective strategies for general prevention of data races are synchronization mechanisms such as mutexes, semaphores, and condition variables, which control access to shared data. These mechanisms ensure that only one thread can access the shared resource at a time \cite{herlihy2008}. Since this work is focusing on data races in interrupt-driven systems, the main tool to prevent data races is to disable \acp{ISR}, which access shared resources in critical areas.
		\newpage
		The following code shows an example for a disable and enable call that lead to the safe access of shared data.
		\begin{lstlisting}
			# Data Race Example with ISR Enable/Disable
			long shared1 = 0;
			
			def main():
			
			unsigned tmp = 0;
			disable_isr(1);
			tmp = shared1;
			enable_isr(1);
			def isr1():
			
			idlerun();
			shared1 = 1;
			idlerun();
			
			main();
		\end{lstlisting}
			
		
		 The \texttt{main()} function and \texttt{isr1()} both access the shared resource \texttt{shared1}. Since the read operation in line 6 of the \texttt{main()} function is safely accessed by disabling \texttt{isr1} in line 5 and enabling it in line 7, a possible data race is prevented.
		
		\section{Static Detection of Data Races in Interrupt-Driven Systems}
		
		The asynchronous nature and concurrent execution of \acp{ISR} and the main function introduce significant challenges for data consistency and detecting data races in interrupt-driven systems. Static data race analyses, especially those who utalize \acp{RICFG}, are a promising approach to identify data races without the need for extensive testing and runtime monitoring as in dynamic approaches \cite{wang2020}.
		
		The static approach involves the construction of an \ac{RICFG} for the program, which includes both the main code and \acp{ISR}, and capturing the control flow and potential interaction between them. Traversion of the \ac{RICFG} using a \Ac{DFS} shows paths where shared resources are accessed concurrently without proper synchronization and indicates potential data races. Integrating the static analysis tool with the development process enables continuous detection of data races during software development, which improves the reliability and correctness of interrupt-driven systems \cite{wang2020}.
		
		The methodology for static data race detection in interrupt-driven systems by Wang et al. involves the following key steps.
		\begin{enumerate}
			\item First, the \acp{RICFG} are constructed for the entire program, including the main code and the \acp{ISR}. This involves analyzing the control flow and identifying interactions between the main program and \acp{ISR}. 
			\item Next, the \acp{RICFG} are analyzed to find potential data races, focusing on paths where concurrent access to shared data is done without proper synchronization. 
			\item Finally, the developer can use the analysis results to address identified data races early in the development process \cite{wang2020}.
		\end{enumerate}
		
		\begin{algorithm}[H]
			\label{algo:srd}
			\caption{Static Race Detection}
			\KwIn{RICFGs of P}
			\KwOut{potential racing pairs (PR)}
			
			\BlankLine
			\For{each $< G_i ; G_j >$ in RICFGs}{
				\For{each $sv_i \in G_i$}{
					\For{each $sv_j \in G_j$}{
						\If{$sv_i.V == sv_j.V$ and $(sv_i.A == W$ or $sv_j.A == W)$ and $G_i.pri < G_j.pri$ and $INTB.get(svi).contains(Gj)$}{
							$PR = PR \cup \{ <sv_i, sv_j> \}$\;
						}
					}
				}
			}
		\end{algorithm}
		
		The \textit{Static Race Detection} algorithm by Wang et al., presented in Algorithm \ref{algo:srd} , takes the \acp{RICFG} of program $P$ as input and outputs the potential racing pairs (PR). For each pair of graphs $< G_i ; G_j >$ in the \acp{RICFG}, the algorithm iterates over each shared variable $sv_i$ in $G_i$ and each shared variable $sv_j$ in $G_j$. If the variables $sv_i$ and $sv_j$ are the same ($sv_i.V == sv_j.V$), at least one of the accesses is a write operation ($(sv_i.A == W$ or $sv_j.A == W)$), the priority of $G_i$ is less than that of $G_j$ ($G_i.pri < G_j.pri$), and the interrupt status table ($INTB$) indicates that the interrupt for $sv_i$ is enabled while $sv_j$ is being accessed, then the pair $<sv_i, sv_j>$ is added to the set of potential racing pairs (PR) \cite{wang2020}.
		
		The following introduces the implementation of new a static analysis program based on the static race detection approach of Wang et al.



\chapter{Implementation}
In the following, this chapter provides an in-depth explanation of the implementation. For the generation of the input, \ac{GCC} is used. The command \texttt{gcc -fdump-tree-cfg} provides a \mbox{\texttt{cfg-file}} with all the important information for the intended data race analysis.

The \texttt{cfg-files} are structured as follows. 
At the start of each function is a commented line with the function name. This line is used to strip the function name in the implementation.
\begin{lstlisting}
;; Function int main() 
\end{lstlisting}

Following the function name, there is summary of every \acl{BB} including their successors. This part is used to add the successors of each \aclp{BB} to their initiated items. 
\begin{lstlisting}
;;  nodes: 0 1 2 3 4 5 6
;; 2 succs { 3 4 }
;; 3 succs { 5 }
;; 4 succs { 5 }
;; 5 succs { 6 }
;; 6 succs { 1 }
\end{lstlisting}
Finally there is the actual execution of each function. It displays each \acl{BB} and what they do. This part is used to find critical lines that access the shared resource or changing the status of an \ac{ISR}.
\begin{lstlisting}
int main() ()
{
	int variable2;
	unsigned char tmp;
	int D.1934;
	long int shared1.2;
	long int shared1.1;
	bool retval.0;
	
	<bb 2>:
	disable_isr (1);
	shared1 = 0;
	shared1.1 = shared1;
	retval.0 = shared1.1 != 0;
	if (retval.0 != 0)
	goto <bb 3>;
	else
	goto <bb 4>;
	
	<bb 3>:
	enable_isr (1);
	goto <bb 5>;
	
	<bb 4>:
	variable2 = 1;
	
	<bb 5>:
	shared1.2 = shared1;
	tmp = (unsigned char) shared1.2;
	enable_isr (1);
	D.1934 = 0;
	
	<L3>:
	return D.1934;
	
}

\end{lstlisting}

\begin{figure}[H]
	\centering
	\begin{tikzpicture}[node distance=2.5cm]
		
		% Define styles only within this scope
		\begin{scope}[
			startstop/.style={rectangle, rounded corners, minimum width=1.5cm, minimum height=1.5cm, text centered, draw=black, fill=red!30},
			process/.style={rectangle, minimum width=1.5cm, minimum height=1.5cm, text centered, draw=black, fill=orange!30},
			arrow/.style={thick,->,>=stealth}
			]
			
			\node (start) [startstop] {\begin{tabular}{c}Input\\Data\end{tabular}};
			\node (parse) [process, right of=start] {\begin{tabular}{c}Parse\\Blocks\end{tabular}};
			\node (dfs) [process, right of=parse] {\begin{tabular}{c}DFS\\Process\\Blocks\end{tabular}};
			\node (detect) [process, right of=dfs] {\begin{tabular}{c}Detect\\Races\end{tabular}};
			\node (filter) [process, right of=detect] {\begin{tabular}{c}Filter\\Races\end{tabular}};
			\node (output) [startstop, right of=filter] {\begin{tabular}{c}Output\\Races\end{tabular}};
			
			\draw [arrow] (start) -- (parse);
			\draw [arrow] (parse) -- (dfs);
			\draw [arrow] (dfs) -- (detect);
			\draw [arrow] (detect) -- (filter);
			\draw [arrow] (filter) -- (output);
			
		\end{scope}
	\end{tikzpicture}
	\caption{Flow Chart of the Program}
	\label{programflowchart}
\end{figure}
Figure \ref{programflowchart} shows the flow of an analysis of such a file. First the input is parsed and generates the \aclp{BB} items, which are then traversed using a \ac{DFS} and processed while traversing through them. With the informations generated by the traversion of the \ac{RICFG} possible data races are detected and saved. Finally correct shared data accesses that meet the criterias used in the data race detection are filtered out of the list of data races.
The explanation of the implementation is split into the initialization of the basic block class, the parsing of the input, the \acl{DFS} to explore all path, the actual data race analysis, and the filtering of false positives found in the data race analysis.


\section{Class BasicBlock}

The class \texttt{BasicBlock} displays all the information necessary for the data race analysis. The \aclp{BB} build the \ac{RICFG} by storing every possible path of the functions in its successors. Each \ac{BB} item also stores all the important informations for the further data race analysis like priority of the function, shared resource access in the \ac{BB}, enable or disable calls of \acp{ISR} and function calls for inter-procedural edges between the function. Those information include the following attributes:
\begin{itemize}
	\item \texttt{function\_name}: The function name to which the basic block belongs.
	\item \texttt{number}: The number of the basic block.
	\item \texttt{priority}: The priority of the function the \ac{BB} is in.
	\item \texttt{shared\_resources}: All accesses of shared resources within the \ac{BB}. The access type (read/write) and the line number of such calls are saved.
	\item \texttt{successors}: A list of all the successors of each basic block. Important for building all possible paths through the CFG.
	\item \texttt{enable\_disable\_calls}: All calls that disable or enable an \ac{ISR} within this basic block and also the corresponding line number of those calls to ensure the correct order.
	\item \texttt{function\_calls}: The functions that are called within a \ac{BB}.
\end{itemize}
Resulting in the following UML class diagram in Figure \ref{uml}:
\begin{figure}[H]
	\centering
	\begin{tikzpicture}
		% Define styles for the different elements of the class diagram
		\tikzstyle{class} = [rectangle, draw, minimum width=10cm, minimum height=1cm, font=\bfseries, fill=blue!20]
		\tikzstyle{attributes} = [rectangle, draw, minimum width=10cm, minimum height=4cm, anchor=north, align=left, fill=blue!10]
		\tikzstyle{methods} = [rectangle, draw, minimum width=10cm, minimum height=5cm, anchor=north, align=left, fill=blue!10]
		
		% Class name
		\node[class] (classname) at (0, 0) {BasicBlock};
		
		% Attributes
		\node[attributes, below=0cm of classname] (attributes) {
			- function\_name: String\\
			- number: int\\
			- priority: int\\
			- shared\_resources: List\\
			- successors: List\\
			- enable\_disable\_calls: List\\
			- function\_calls: List
		};
		
		% Methods
		\node[methods, below=0cm of attributes] (methods) {
			+ BasicBlock(\\
			\hspace*{5mm} function\_name: String,\\
			\hspace*{5mm} number: int,\\
			\hspace*{5mm} priority: int,\\
			\hspace*{5mm} shared\_resources: List = [],\\
			\hspace*{5mm} successors: List = [],\\
			\hspace*{5mm} enable\_disable\_calls: List = [],\\
			\hspace*{5mm} function\_calls: List = [])
		};
		
		% Draw the borders
		\draw (classname.north west) rectangle (methods.south east);
		\draw (attributes.north west) -- (attributes.north east);
		\draw (methods.north west) -- (methods.north east);
	\end{tikzpicture}
	\caption{UML: Class BasicBlock}
	\label{uml}
\end{figure}

\section{Parsing and Helper Functions}
This section explains the parsing of the input and the helper functions, which are called in the data race analysis.

The parsing of the input iterates two times through the code lines to extract all the important information of the code and save it in the \ac{BB} items. The first iteration of the code lines initiates the \acp{BB} with the \ac{BB} number and the function it relates to.
Using these regular expression:
\begin{lstlisting}
	func_match = re.match(r';; Function (.+?) \(', line)
	bb_match = re.match(r'<bb (\d+)>:', line)
\end{lstlisting}
Additionally, it adds the information of shared resources, enable/disable calls of \acp{ISR} and function calls within the \ac{BB}.
To identify the shared reources and their operation type these regular expression are used:
\begin{lstlisting}
	re.search(fr'\b{resource_name}\b', line)
	re.search(fr'\b{resource_name}\b\s*=', line) and not re.search(fr'\b{resource_name}\b\s*==', line)
\end{lstlisting}
The second iteration adds the successors of the \ac{BB}, using this regular expression:
\begin{lstlisting}
	succ_match = re.match(r';; (\d+) succs \{(.+?)\}', line)
\end{lstlisting}
A second iteration is used to ensure all the \acp{BB} items are initialized first to ensure a correct handling of the successors.

There are also multiple helper functions, which are called during the data race analysis part of the implementation. 

The \texttt{determine\_priority} function is determining the priority of the function which is involved in a possible data race. Since one condition for a data race is that the interrupting function has a higher priority, this is an important check. The function uses a regular expression to find the number of a \ac{ISR} to use that as its priority.
\begin{lstlisting}
	match = re.search(r'isr[_]?(\d+)', function_name)
\end{lstlisting}
The priority is determined in the first place by differentiating between \ac{ISR} functions and normal functions because \acp{ISR} always have a higher priority than non-\ac{ISR} functions. In this implementation non-\Ac{ISR} functions have the priority infinity and \acp{ISR} are ordered by the number of it, while lower number \acp{ISR} have a higher priority than higher number ones.
	
The \texttt{propagate\_function\_calls} function is handling the case of a function that calls another function. It checks for \acp{BB} items with a function call in it and adds the critical parts of the called function to the current \ac{BB} to simulate a path through the called function and consider the shared resources and enable/disable calls of that function.

\section{Data Race Detection}
The following algorithms are used to determine all possible data races, which are filtered later in the code. The intention is to find all possible data races to minimize the number of false negatives. Since false positives can be evaluated later by interpreting the output. The algorithm are ordered as they are found in the code. All the following algorithms are part of the \texttt{detect\_data\_race} function in the code. The \ac{DFS} algorithm is exploring all possible paths thorugh the \ac{CFG} while calling the Algorithm 4 Process Block, which processes the shared resources and enable or disable calls within the \ac{BB} in order. It appends the shared resources to a list \texttt{resource\_access} and updates the \texttt{current\_isr\_status}. The resource access list is then used in the Alogrithm 7 Check for Data Races, where it finds possible data races using the critical criterias of a data race. In the end the Algorithm 8 Filter Data Races is using the \texttt{isr\_status} aswell as the \texttt{isr\_enabling\_map} to filter out correctly accessed shared resources.

The first part of the function \texttt{detect\_data\_races} takes a list of all basic block items as input. It also initializes the empty list of \texttt{potential\_data\_races}, a dictionary for \texttt{resource\_access}, and a dictionary for the \texttt{isr\_enabling\_map}. \texttt{Potential\_data\_races} and \texttt{resource\_access} are used later in the code.

\begin{algorithm}[H]
	\caption{ISR Enabling Map}
	\label{algo:isrmap}
	\DontPrintSemicolon
	\SetAlgoLined
	\KwData{blocks}
	\KwResult{List ISR enabling ISRs filled}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
	\KwIn{Dictionary of BasicBlocks}
	\KwOut{List of enabling ISRs}
	\BlankLine
	potential\_data\_races $\gets$ empty list\;
	resource\_accesses $\gets$ initialize as a default dictionary to list\;
	isr\_enabling\_map $\gets$ initialize as a default dictionary to set\;
	\BlankLine
	\ForEach{block in blocks}{
		\ForEach{call, line\_number in block.enable\_disable\_calls}{
			\If{call contains 'enable\_isr'}{
				isr\_idx\_match $\gets$ search for isr number in call;\\
				\If{isr\_idx\_match is found}{
					enabled\_isr\_idx $\gets$ integer value of the first group in isr\_idx\_match minus one\;
					enabler\_isr $\gets$ block.function\_name\;
					isr\_enabling\_map[enabler\_isr].add(enabled\_isr\_idx)\;
				}
			}
		}
	}
\end{algorithm}

\vspace{1cm}
The main loop of the Algorithm \ref{algo:isrmap} iterates through every item in blocks and finds basic blocks with \texttt{enable\_disable\_calls}. If there is an enable call in a block item, the index of the enabled \ac{ISR} is read, and the basic block is added to the \texttt{isr\_enabling\_map} with the information on which \ac{ISR} it enables.

\begin{algorithm}[H]
	\caption{Process Block}
	\label{algo:PB}
	\DontPrintSemicolon
	\SetAlgoLined
	\KwData{block, current\_isr\_status}
	\KwResult{Updated ISR status and recorded resource accesses}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
	\KwIn{A code block and the current ISR status as a list}
	\KwOut{Updated current ISR status and appended resource accesses to a global list}
	\BlankLine
	combined\_events $\gets$ sort(block.shared\_resources + block.enable\_disable\_calls, key=\texttt{lambda} x: x[2] if len(x) == 3 else x[1])\;
	\ForEach{event in combined\_events}{
		\If{event is a shared resource access (\texttt{len(event) == 3})}{
			resource\_name, access\_type, res\_line\_number $\gets$ event\;
			resource\_accesses[resource\_name].append((block.function\_name, block.number, access\_type, res\_line\_number, current\_isr\_status.copy(), block.priority))\;
		}
		\ElseIf{event is an enable/disable ISR call (\texttt{len(event) == 2})}{
			call, line\_number $\gets$ event\;
			isr\_idx\_match $\gets$ search for ISR number in call\;
			\If{isr\_idx\_match is found}{
				isr\_idx $\gets$ integer value of the first group in isr\_idx\_match minus one\;
				\eIf{"disable\_isr" is in call}{
					\If{0 $\leq$ isr\_idx $<$ length of current\_isr\_status}{
						current\_isr\_status[isr\_idx] $\gets$ 1\;  % Assuming 1 indicates disabled
					}
				}{
					\If{0 $\leq$ isr\_idx $<$ length of current\_isr\_status}{
						current\_isr\_status[isr\_idx] $\gets$ 0\;  % Assuming 0 indicates enabled
					}
				}
			}
		}
	}
\end{algorithm}
\vspace{1cm}

Algorithm \ref{algo:PB} iterates through each line of a basic block to find the current \ac{ISR} status while resources are accessed. It sorts each access of shared resources and the enable or disable calls of \acp{ISR} by line number to ensure the correct order of execution. The algorithm differs between shared resource access and \Ac{ISR} enable or disable calls by the length of the event. Accesses have three entries, the resource name, the access type and the line number and the enable and disable calls have two entries the call and the line number. When a resource is found, all the information is added to the \texttt{resource\_accesses} dictionary, which includes the function name and the block number of the current basic block, as well as the access type, the line number, and the \ac{ISR} status of the access. If an enable or disable call is found the algorithm changes the corresponding bit in the \texttt{current\_isr\_status} array to a 1 for diable calls and to a 0 for enable calls. All this information is used later for the detection and filter of data races.

\begin{algorithm}[H]
	\caption{\ac{DFS} and Initialization}
	\label{algo:dfs+init}
	\DontPrintSemicolon
	\SetAlgoLined
	\KwData{blocks}
	\KwResult{Updated block ISR statuses and processed blocks}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
	\KwIn{Dictionary of basic blocks}
	\KwOut{Updated block ISR statuses}
	\BlankLine
	
	\SetKwProg{Fn}{Function}{:}{}
	\Fn{dfs(block, visited\_blocks, current\_isr\_status, path)}{
		\If{(block.function\_name, block.number) \textbf{in} visited\_blocks}{
			block\_isr\_statuses[(block.function\_name, block.number)] $\gets$ merge\_isr\_statuses(block\_isr\_statuses[(block.function\_name, block.number)], current\_isr\_status)\;
			\Return\;
		}
		visited\_blocks.add((block.function\_name, block.number))\;
		path.append((block.function\_name, block.number))\;
		
		block\_isr\_statuses[(block.function\_name, block.number)] $\gets$ current\_isr\_status.copy()\;
		process\_block(block, current\_isr\_status)\;
		
		\If{not block.successors}{
			\Return\;
		}
		\Else{
			\For{successor \textbf{in} block.successors}{
				dfs(successor, set(visited\_blocks), current\_isr\_status.copy(), path.copy())\;
			}
		}
	}
	
	\BlankLine
	\tcp{Initialization and starting DFS from basic blocks with number 2}
	\For{(func\_name, bb\_num), block \textbf{in} blocks.items()}{
		\If{bb\_num == 2}{
			initial\_isr\_status $\gets$ track\_isr\_status(blocks).copy()\;
			process\_block(block, initial\_isr\_status)\;
			\For{successor \textbf{in} block.successors}{
				dfs(successor, set(), initial\_isr\_status.copy(), [(func\_name, bb\_num)])\;
			}
		}
	}
\end{algorithm}
\vspace{1cm}

The Algorithm \ref{algo:dfs+init} is recursively processing each block in a possible path of the \ac{RICFG}. The set \texttt{visited\_blocks} is used to avoid revisiting already visited blocks. If the block is already visited, the \ac{ISR} status is updated with the stored \ac{ISR} status for that block using the \texttt{merge\_isr\_statuses} function. The \ac{DFS} always is initiated at \ac{BB} number two.

\begin{algorithm}[H]
	\label{Mergeisr}
	\caption{Merge ISR Statuses}
	\DontPrintSemicolon
	\SetAlgoLined
	\KwData{isr\_status1, isr\_status2}
	\KwResult{Merged ISR status list}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
	\KwIn{Two lists of ISR statuses}
	\KwOut{List of merged ISR statuses}
	\BlankLine
	merged\_status $\gets$ empty list\;
	\For{isr1, isr2 \textbf{in} zip(isr\_status1, isr\_status2)}{
		merged\_status.append(min(isr1, isr2))\;
	}
	\Return{merged\_status}\;
\end{algorithm}

\vspace{1cm}

Alogrithm \ref{Mergeisr} takes the worst case of the most enabled \acp{ISR} and uses this for further analysis of the path.

Unvisited blocks get added to the \texttt{visited\_blocks} set and to the path list. After that, the \ac{ISR} status gets updated to the current \ac{ISR} status, and the function \texttt{process\_block} is called to update the \ac{ISR} status and track the shared resource accesses.

When the block is processed, the function checks for possible successors and recursively calls itself with the successor and the updated copy of \texttt{visited\_blocks}, \texttt{current\_isr\_status}, and the path.

The first \ac{BB} in a function is always the \ac{BB} with number two in the generated cfg-files. To initialize the \ac{DFS}, the \ac{BB} number 2 is processed by the \texttt{process\_block} function, and after that, the \ac{DFS} function is called with the successor of the current block.

\begin{algorithm}[H]
	\label{checkdr}
	\caption{Check for Data Races}
	\DontPrintSemicolon
	\SetAlgoLined
	\KwData{resource\_accesses}
	\KwResult{List of potential data races}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
	\KwIn{Dictionary of resource accesses}
	\KwOut{List of potential data races}
	\BlankLine
	\SetKwFunction{FMain}{check\_for\_data\_races}
	\SetKwProg{Fn}{Function}{:}{}
	\Fn{\FMain{}}{
		\For{resource, accesses \textbf{in} resource\_accesses.items()}{
			\For{i, (func1, bb\_num1, access\_type1, line\_number1, isr\_status1, priority1) \textbf{in} enumerate(accesses)}{
				\For{j, (func2, bb\_num2, access\_type2, line\_number2, isr\_status2, priority2) \textbf{in} enumerate(accesses)}{
					\If{i $\geq$ j}{
						Continue\;
					}
					\If{func1 $\neq$ func2 \textbf{and} (access\_type1 == "write" \textbf{or} access\_type2 == "write") \textbf{and} priority1 $\neq$ priority2}{
						potential\_data\_races.append((resource, (func1, bb\_num1, access\_type1, line\_number1, isr\_status1, priority1),
						(func2, bb\_num2, access\_type2, line\_number2, isr\_status2, priority2)))\;
					}
				}
			}
		}
	}
\end{algorithm}
\vspace{1cm}

The Algorithm \ref{checkdr} identifies potential data races by comparing the pairs of data accesses that were initiated earlier. It iterates through all possible tuples of accesses. If a tuple is not within the same function, one of the two accesses is a write operation, and the priorities of both accesses are different, the pair is added to the list of possible data races. All the items in the list fulfill the conditions of a possible data race, which do not include the \ac{ISR} status tracking. Since the \ac{ISR} status tracking is the more complex part of the analysis, this makes sure to find all possible data races before filtering to minimize the number of false negatives.

\section{Filter of Possible Data Races}

\begin{algorithm}[H]
	\label{filterdr}
	\caption{Filter Data Races}
	\DontPrintSemicolon
	\SetAlgoLined
	\KwData{potential\_data\_races, isr\_enabling\_map}
	\KwResult{Filtered list of data races}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
	\KwIn{List of potential data races, ISR enabling map}
	\KwOut{List of filtered data races}
	\BlankLine
	
	filtered\_data\_races $\gets$ empty list\;
	seen\_races $\gets$ empty set\;
	
	\For{resource, access1, access2 \textbf{in} potential\_data\_races}{
		func1, line\_number1, isr\_status1, $\gets$ access1\;
		func2, line\_number2, isr\_status2, $\gets$ access2\;
		
		relevant\_isr\_disabled1 $\gets$ is\_isr\_disabled(isr\_status1, func2) \textbf{and} not is\_isr\_enabled\_by\_another(isr\_status1, func2)\;
		relevant\_isr\_disabled2 $\gets$ is\_isr\_disabled(isr\_status2, func1) \textbf{and} not is\_isr\_enabled\_by\_another(isr\_status2, func1)\;
		
		race\_key $\gets$ frozenset(((func1, line\_number1), (func2, line\_number2)))\;
		
		\If{not (relevant\_isr\_disabled1 \textbf{or} relevant\_isr\_disabled2) \textbf{and} race\_key not \textbf{in} seen\_races}{
			filtered\_data\_races.append((resource, access1, access2))\;
			seen\_races.add(race\_key)\;
		}
	}
	
	\Return{filtered\_data\_races}\;
\end{algorithm}
\vspace{1cm}

The Algorithm \ref{filterdr} takes the list of possible data races given by the \texttt{check\_for\_data\_races} function and filters the racing pairs considering the \ac{ISR} statuses of the involved \acp{ISR}. It takes the two accesses of a potential race and extracts the information that is saved in those accesses. After that, it uses two helper functions to determine the \ac{ISR} statuses during the access.

\begin{algorithm}[H]
	\label{isrdis}
	\caption{Is ISR Disabled}
	\DontPrintSemicolon
	\SetAlgoLined
	\KwData{isr\_status, func\_name}
	\KwResult{Boolean indicating if the ISR is disabled}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
	\KwIn{List of ISR statuses, function name as a string}
	\KwOut{Boolean}
	\BlankLine
	
	isr\_idx $\gets$ extract\_isr\_index(func\_name)\;
	\If{isr\_idx is not None \textbf{and} isr\_idx $<$ length of isr\_status}{
		\Return{isr\_status[isr\_idx] == 1}\;
	}
	\Return{False}\;
\end{algorithm}
\vspace{1cm}


The Algorithm \ref{isrdis} checks if the bit corresponding to the \ac{ISR} in the \Ac{ISR} status array is set to one. An \Ac{ISR} is disabled with a one in its corresponding bit in the \ac{ISR} status list and enabled with an 0. If so, the function returns true to the \texttt{filter\_data\_races} function, and if not, it returns false. 
\vspace{1cm}

\begin{algorithm}[H]
	\label{isrenab}
	\caption{Is ISR Enabled by Another}
	\DontPrintSemicolon
	\SetAlgoLined
	\KwData{isr\_status, func\_name, isr\_enabling\_map}
	\KwResult{Boolean indicating if the ISR is enabled by another function}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
	\KwIn{List of ISR statuses, function name as a string, ISR enabling map}
	\KwOut{Boolean}
	\BlankLine
	
	isr\_idx $\gets$ extract\_isr\_index(func\_name)\;
	\If{isr\_idx is not None}{
		\For{enabler\_isr, enabled\_isrs \textbf{in} isr\_enabling\_map.items()}{
			enabler\_idx $\gets$ extract\_isr\_index(enabler\_isr)\;
			\If{enabler\_idx is not None \textbf{and} not is\_isr\_disabled(isr\_status, enabler\_isr)}{
				\If{isr\_idx \textbf{in} enabled\_isrs}{
					\Return{True}\;
				}
			}
		}
	}
	\Return{False}\;
\end{algorithm}
\vspace{1cm}

The Algorithm \ref{isrenab} looks for possible activations of an \ac{ISR} by another \ac{ISR}. The \texttt{isr\_enabling\_map} was initiated and filled with information at the start of the \texttt{detect\_data\_races} function. This information is used in this function to determine if an \ac{ISR} is enabled by another \ac{ISR} that is enabled, to correctly handle racing pairs with these conditions.

\chapter{Evaluation}

The efficiency and effectiveness of the implemented static data race detection framework were evaluated using the benchmarks provided by the racebench 2.1 GitHub repository\footnote{\href{https://github.com/chenruibuaa/racebench/tree/master/2.1}{https://github.com/chenruibuaa/racebench/tree/master/2.1}}.
To cover a wider range of scenarios, some benchmarks were added to specifically evaluate considered cases.
The benchmarks are all manually checked for data races to compare the expected data races found and the actual number found by the analysis tool. Since part of the work is also the reduction of the computing overhead by reducing the \acp{ICFG}, the analysis time of the program is also added to the evaluation.
\begin{table}[H]
	\centering
	\scalebox{0.8}{
		\begin{tabular}{|l|c|c|c|c|}
			\hline
			\textbf{Benchmark} & \textbf{\#ISR} & \textbf{\#Func} & \textbf{\#SR} & \textbf{\#BB} \\
			\hline
			Simple Enable/Disable Calls & 2 & 3 & 1 & 7 \\
			\hline
			Multiple Resources & 2 & 3 & 2 & 7 \\
			\hline
			ISR Enabling & 2 & 3 & 1 & 7 \\
			\hline 
			Function Calls & 2 & 4 & 1 & 5 \\
			\hline
			ISR Enabling 2 & 3 & 4 & 4 & 13 \\
			\hline
			ISR Enabling Depth & 3 & 4 & 4 & 13 \\
			\hline
			svp\_simple\_006\_001 & 1 & 2 & 2 & 24 \\
			\hline
			svp\_simple\_012\_001 & 1 & 2 & 1 & 2 \\
			\hline
			svp\_simple\_014\_001 & 3 & 4 & 4 & 13 \\
			\hline
			svp\_simple\_019\_001 & 1 & 2 & 8 & 15 \\
			\hline
		\end{tabular}
	}
	\caption{Objects of Analysis}
	\label{objects}
\end{table}

Table \ref{objects} shows a summary of the important characteristics of the used benchmarks. The number of \acp{ISR}, functions, shared resources, and basic blocks is shown for each \ac{CFG}. These numbers help to have a brief understanding of the depth of each function without actually understanding the \texttt{cfg-file} of each of those benchmarks.

\begin{table}[H]
	\centering
	\scalebox{0.8}{
		\begin{tabular}{|l|c|c|c|}
			\hline
			\textbf{Benchmark} & \textbf{Manual} & \textbf{Program} & \textbf{Time (seconds)} \\
			\hline
			Simple Enable/Disable Calls & 2 & 2 & 0.007 \\
			\hline
			Multiple Resources & 3 & 3 & 0.004 \\
			\hline
			ISR Enabling & 2 & 2 & 0.006 \\
			\hline
			Function Calls & 4 & 4 & 0.005 \\
			\hline
			ISR Enabling 2 & 8 & 8 & 0.004 \\
			\hline
			ISR Enabling with Depth & 8 & 4 & 0.009 \\
			\hline
			svp\_simple\_006\_001 & 4 & 4 & 0.002 \\
			\hline
			svp\_simple\_012\_001 & 2 & 1 & 0.002 \\
			\hline
			svp\_simple\_014\_001 & 8 & 8 & 0.004 \\
			\hline
			svp\_simple\_019\_001 & 10 & 10 & 0.006 \\
			\hline
		\end{tabular}
	}
	\caption{Comparison of Manual and Program-Detected Data Races}
	\label{results}
\end{table}

Table \ref{results} displays the results of the evaluation with suited \acp{CFG} . The benchmarks are chosen to show most of the cases that were considered when developing the data race detection framework. Those evaluated cases include simple enable/disable calls, access of multiple shared resources, \Ac{ISR} enabling \acp{ISR}, inter-procedural function calls and deep if-else chains. The execution times are determined with the \texttt{time} module in python and it tracks the time after entering the input until completed execution of the analysis. The program reliably detects data races within the considered scenarios. It successfully keeps track of every enable and disable call of \acp{ISR} as well as considering all the other criteria for a data race shown earlier like priority, access type, and so on. In the program \texttt{ISR Enabling with Depth}, an \ac{ISR} enabling map with a depth of two would be needed to detect all eight data races, which is not included in this work. \texttt{svp\_simple\_012\_001} uses pointers, which also leads to false negatives with the current implementation. All the used benchmarks can be found in the GitHub reposetory of this work\footnote{\href{https://github.com/RobinWillenbrock/BADataRaces/tree/main/Code/Benchmarks}{https://github.com/RobinWillenbrock/BADataRaces/tree/main/Code/Benchmarks}}.
The runtime of the program stays consistently low within the testing with the benchmarks of racebench 2.1.


 
 \chapter{Discussion}
This thesis presents a static analysis framework for detecting data races in interrupt-driven software using \aclp{RICFG}. The approach efficiently identifies potential data races by analyzing the software's source code and focusing on essential control flow elements and code lines. This discussion highlights the completed aspects of the implementation, the current limitations, and the potential enhancements of the analysis program.

The framework detects data races effectively by meeting the essential criteria, such as identifying shared resources in the input and their operation type as well as the priority they are used with.

The provided \texttt{cfg-file} is interpreted and used to develop a \acl{RICFG}. The interprocedural calls of functions are stored in the \acl{BB} items and used to analyze the edges between functions. In the current implementation, the critical information of called functions is added to the currently processed \ac{BB}. This can be further improved by adding the calls into the \ac{DFS} to ensure all possible interactions are considered. This could improve the stability of the inter-procedural analysis compared to the current implementation.

The reduction of the generated \ac{ICFG} is realized by reducing the information each \acl{BB} carries to a minimum needed for the analysis. Only the critical lines of the \ac{CFG} get stored in the \aclp{BB}, which form the \ac{RICFG}. To ensure a flawless path through the graph, the nodes are not deleted when they do not carry any important information but are left empty to minimize the computational overhead the program has to execute. Nonetheless, it can be further optimized by completely removing the nodes and passing the successors. For larger \acp{CFG}, this would be an improvement, but for smaller \acp{CFG}, the current approach is comparable because it does not add the computation of the successor handling.

The \acp{CFG} are traversed with a \ac{DFS} algorithm that ensures all possible paths are discovered. In a \ac{DFS}, one missing successor can lead to an incomplete path and result in missing possible data races. As mentioned earlier, this is the reason this work focuses on the correctness of the path over the possible reduction of the computation by not deleting the \ac{BB} completely and keeping them empty with only the successors.

Additionally, the \ac{ISR} status array is implemented and dynamically updated through the \ac{CFG} traversal. By adding the enable and disable calls of a \acl{BB} with their corresponding code lines to the item, an efficient way of traversing through the \ac{CFG} is enabled while keeping the execution flow correct even within a \acl{BB}. The array ensures a correct handling of every \ac{ISR} status change. This results in a significant reduction of false positives and an easier interpretation of the data races that are found.

As an improvement to the prior work of Wang et al., this work implemented a solution to \ac{ISR} enabling \acp{ISR}. By introducing an \ac{ISR} enabling map, all the \ac{ISR} enable operations of other \acp{ISR} are considered. This leads to detected data races with the corresponding \ac{ISR} being disabled, which can then be further analyzed by the developer.

All in all, the program stores the minimal information needed for the analysis in different \acl{BB} items which form an \ac{RICFG}. This \acp{RICFG} is then traversed by a \ac{DFS} algorithm to find all possible data races while considering the \ac{ISR} status at any point, including \ac{ISR} enabling \acp{ISR}.

The current implementation does not include a pointer analysis, which leads to possible false negatives. The framework can be further improved by adding a pointer analysis, which would improve the precision of the tool. Since there are several tools for such analysis, this work focused on the implementation of other critical parts of the data race analysis such as the \ac{ISR} handling.

Furthermore, the handling of \ac{ISR} enabling \acp{ISR} is currently limited to a depth of one. The program can be further improved to find possible enable operations of other \acp{ISR} in greater depth. Since the scenarios of multiple \acp{ISR} enabling each other consecutively in the correct order to lead to a data race are very rare, this work is not considering those cases.

 
\chapter{Conclusion}
This thesis presents a static analysis tool for detecting data races in interrupt-driven software. By using \aclp{RICFG}, the tool effecitvely identifies potential data races by focusing on essential control flow elements and shared resource accesses. The \ac{DFS} alogrithm ensures exploration of all possible paths, while keeping track of the \ac{ISR} status of each \ac{ISR} at any point of the control flow.

The evaluation of the framework using a variety of benchmarks, including the ones from the racebench 2.1 repository and self optimized ones to display special cases, demonstrate the effiency and accuracy of the program in different scenarios. The results show a reliable identification of data races while maintaining a low computional overhead.

The current implementation still has limitations, such as the handling of pointers and the depth of \ac{ISR} enabling scenarios. Future work could focus on then integration of a pointer analysis tool to further improve the precision of the framework. On top of that the \ac{ISR} enabling map can be improved by considering the enable operations in further depth. Additionally the implementation of the \ac{RICFG} can be further optimized by completely removing \aclp{BB} without important informations while maintaining the correct control flow.

In conclusion, the developed static data race detection framework provides a valuable tool, which enables early detection of data races in interrupt-driven software. 


\appendix

\backmatter{}
\begin{thebibliography}{9}
	\bibitem{wang2020}
	Wang, Y., Gao, F., Wang, L., Yu, T., Zhao, J., \& Li, X. (2020). Automatic Detection, Validation, and Repair of Race Conditions in Interrupt-Driven Embedded Software. IEEE Transactions on Software Engineering.
	
	\bibitem{engler2003}
	Engler, D., \& Ashcraft, K. (2003). RacerX: Effective, Static Detection of Race Conditions and Deadlocks. ACM SIGOPS Operating Systems Review.
	
	\bibitem{chopra2019}
	Nikita Chopra, Rekha Pai, and Deepak D’Souza (2019). Data Races and Static Analysis for Interrupt-Driven Kernels
	
	\bibitem{flanagan2009}
	Flanagan, C., \& Freund, S. N. (2009). FastTrack: Efficient and Precise Dynamic Race Detection. ACM SIGPLAN Notices.
	
	\bibitem{chen2011}
	R. Chen, Xiangying Guo, Y. Duan, B. Gu, Mengfei Yang (2011). Static Data Race Detection for Interrupt-Driven Embedded Software.
			
	\bibitem{muchnick1997}
	Muchnick, S. S. (1997). Advanced Compiler Design and Implementation. Morgan Kaufmann.
		
	\bibitem{herlihy2008}
	Herlihy, M., \& Shavit, N. (2008). The Art of Multiprocessor Programming. Morgan Kaufmann.
	
	\bibitem{mehl2008}
	K. Mehlhorn, P. Sanders (2008). Algorithms and Data Structures The Basic Toolbox.
\end{thebibliography}
\chapter{Attachments}
\begin{lstlisting}[language=Python, mathescape, escapeinside={(*}{*)}]
	class BasicBlock:
	def __init__(function_name, number, shared_resources=[], successors=[], enable_disable_calls=[], code=[]):
	self.function_name = function_name
	self.number = number
	self.shared_resources = shared_resources
	self.successors = successors
	self.enable_disable_calls = enable_disable_calls
	self.code = code
	
	def __repr__():
	return ("BasicBlock(function_name={}, number={}, shared_resources={}, "
	"successors={}, enable_disable_calls={}, code={})".format(
	self.function_name, self.number, self.shared_resources, 
	[succ.number for succ in self.successors], self.enable_disable_calls, 
	' '.join(self.code)))
	
	def parse_basic_blocks(file_path, shared_resource_names):
	blocks = {}
	current_function = None
	
	with open(file_path, 'r') as file:
	lines = file.readlines()
	
	bb_num = None
	shared_resources = []
	enable_disable_calls = []
	code_lines = []
	line_number = 0  
	
	for line in lines:
	line = line.strip()
	line_number += 1
	
	func_match = re.match(r';; Function (.+?) \(', line)
	if func_match:
	if bb_num is not None and current_function is not None:
	blocks[(current_function, bb_num)] = BasicBlock(
	current_function, bb_num, shared_resources, [], enable_disable_calls, code_lines)
	current_function = func_match.group(1)
	bb_num = None
	continue
	
	bb_match = re.match(r'<bb (\d+)>:', line)
	if bb_match:
	if bb_num is not None and current_function is not None:
	blocks[(current_function, bb_num)] = BasicBlock(
	current_function, bb_num, shared_resources, [], enable_disable_calls, code_lines)
	bb_num = int(bb_match.group(1))
	shared_resources = []
	enable_disable_calls = []
	code_lines = []
	
	for resource_name in shared_resource_names:
	if re.search(fr'\b{resource_name}\b', line):
	if re.search(fr'\b{resource_name}\b\s*=', line):
	shared_resources.append((resource_name, 'write', line_number))
	else:
	shared_resources.append((resource_name, 'read', line_number))
	
	if 'enable_isr' in line or 'disable_isr' in line:
	enable_disable_calls.append((line.strip(), line_number))
	
	code_lines.append((line, line_number))
	
	if bb_num is not None and current_function is not None:
	blocks[(current_function, bb_num)] = BasicBlock(
	current_function, bb_num, shared_resources, [], enable_disable_calls, code_lines)
	
	current_function = None
	bb_num = None
	for line in lines:
	line = line.strip()
	
	func_match = re.match(r';; Function (.+?) \(', line)
	if func_match:
	current_function = func_match.group(1)
	bb_num = None
	continue
	
	if 'succs' in line:
	succ_match = re.match(r';; (\d+) succs \{(.+?)\}', line)
	if succ_match:
	bb_num = int(succ_match.group(1))
	succ_list = [int(succ.strip()) for succ in succ_match.group(2).split()]
	if (current_function, bb_num) in blocks:
	blocks[(current_function, bb_num)].successors = [
	blocks[(current_function, succ)] for succ in succ_list if (current_function, succ) in blocks]
	
	return blocks
	
	def track_isr_status(blocks):
	isr_count = len(set(block.function_name for block in blocks.values() if re.search(r'isr[_]?\d+', block.function_name)))
	return [0] * isr_count  
	
	def extract_isr_index(function_name):
	match = re.search(r'isr[_]?(\d+)', function_name)
	if match:
	return int(match.group(1)) - 1
	return None
	
	def detect_data_races(blocks):
	potential_data_races = []
	resource_accesses = defaultdict(list)
	isr_enabling_map = defaultdict(set)
	
	for block in blocks.values():
	for call, line_number in block.enable_disable_calls:
	if 'enable_isr' in call:
	isr_idx_match = re.search(r'\((\d+)\)', call)
	if isr_idx_match:
	enabled_isr_idx = int(isr_idx_match.group(1)) - 1
	enabler_isr = block.function_name
	isr_enabling_map[enabler_isr].add(enabled_isr_idx)
	
	def process_block(block, current_isr_status):
	for line, line_number in block.code:
	if 'enable_isr' in line or 'disable_isr' in line:
	isr_idx_match = re.search(r'\((\d+)\)', line)
	if isr_idx_match:
	isr_idx = int(isr_idx_match.group(1)) - 1  
	if "disable_isr" in line:
	if 0 <= isr_idx < len(current_isr_status):
	current_isr_status[isr_idx] = 1
	elif "enable_isr" in line:
	if 0 <= isr_idx < len(current_isr_status):
	current_isr_status[isr_idx] = 0
	
	
	for resource_name, access_type, res_line_number in block.shared_resources:
	if res_line_number == line_number:
	resource_accesses[resource_name].append((block.function_name, block.number, access_type, line_number, current_isr_status.copy()))
	
	def dfs(block, visited_blocks, current_isr_status, path):
	if (block.function_name, block.number) in visited_blocks:
	return
	visited_blocks.add((block.function_name, block.number))
	path.append((block.function_name, block.number))
	
	process_block(block, current_isr_status)
	
	if not block.successors:
	pass
	else:
	for successor in block.successors:
	dfs(successor, set(visited_blocks), current_isr_status.copy(), path.copy())
	
	
	for (func_name, bb_num), block in blocks.items():
	if bb_num == 2:  
	initial_isr_status = track_isr_status(blocks).copy()
	process_block(block, initial_isr_status)
	for successor in block.successors:
	dfs(successor, set(), initial_isr_status.copy(), [(func_name, bb_num)])
	
	
	def check_for_data_races():
	for resource, accesses in resource_accesses.items():
	for i, (func1, bb_num1, access_type1, line_number1, isr_status1) in enumerate(accesses):
	for j, (func2, bb_num2, access_type2, line_number2, isr_status2) in enumerate(accesses):
	if i >= j:
	continue  
	if func1 != func2 and (access_type1 == "write" or access_type2 == "write"):
	potential_data_races.append((resource, (func1, bb_num1, access_type1, line_number1, isr_status1),
	(func2, bb_num2, access_type2, line_number2, isr_status2)))
	
	check_for_data_races()
	
	
	def filter_data_races(potential_data_races):
	filtered_data_races = []
	for resource, access1, access2 in potential_data_races:
	func1, bb_num1, access_type1, line_number1, isr_status1 = access1
	func2, bb_num2, access_type2, line_number2, isr_status2 = access2
	
	def is_isr_disabled(isr_status, func_name):
	isr_idx = extract_isr_index(func_name)
	if isr_idx is not None and isr_idx < len(isr_status):
	return isr_status[isr_idx] == 1
	return False
	
	def is_isr_enabled_by_another(isr_status, func_name):
	isr_idx = extract_isr_index(func_name)
	if isr_idx is not None:
	for enabler_isr, enabled_isrs in isr_enabling_map.items():
	enabler_idx = extract_isr_index(enabler_isr)
	if enabler_idx is not None and not is_isr_disabled(isr_status, enabler_isr):
	if isr_idx in enabled_isrs:
	return True
	return False
	
	relevant_isr_disabled1 = is_isr_disabled(isr_status1, func2) and not is_isr_enabled_by_another(isr_status1, func2)
	relevant_isr_disabled2 = is_isr_disabled(isr_status2, func1) and not is_isr_enabled_by_another(isr_status2, func1)
	
	if not (relevant_isr_disabled1 or relevant_isr_disabled2):
	filtered_data_races.append((resource, access1, access2))
	
	return filtered_data_races
	
	filtered_data_races = filter_data_races(potential_data_races)
	
	return filtered_data_races
	
	
	shared_resource_input = input("Enter the names of shared resources, separated by commas: ")
	shared_resource_names = [name.strip() for name in shared_resource_input.split(',')]
	
	file_path = input("Enter the file path: ").strip()
	blocks = parse_basic_blocks(file_path, shared_resource_names)
	
	data_races = detect_data_races(blocks)
	
	print("Detected Data Races:")
	for resource, access1, access2 in data_races:
	print(f"Resource: {resource}")
	print(f"  Access 1: Function {access1[0]} (BB {access1[1]}), {access1[2]}, Line {access1[3]}, ISR Status: {access1[4]}")
	print(f"  Access 2: Function {access2[0]} (BB {access2[1]}), {access2[2]}, Line {access2[3]}, ISR Status: {access2[4]}")
	print()
\end{lstlisting}
\end{document}